{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca74a7c-d12d-4f3f-b6cb-bc33992307bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff921404-2b0e-4e5c-86e9-637ea4f1ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_beamline_simulation.u_net import ImageProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027625a2-20a7-4984-aa16-e122f22d3664",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "File path for train images\n",
    "training images are the initial intensity of SRX beamline\n",
    "the output is the output of the SRX beamline\n",
    "\"\"\"\n",
    "train_file = \"../NSLS-II-CSX-1-beamline-rsOptExport/rsopt-srw-20220127150906/datasets/results.h5\"\n",
    "output_file = \"../image_data/Intensity-At-Sample-63-3m.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd44a781-2217-4b82-9bad-8ee7be8085ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "file path for test images\n",
    "testing images are the initial intensity of CSX\n",
    "the output is the output of the CSX beamline with varied aperture \n",
    "horizontal and vertical is 0.1\n",
    "\"\"\"\n",
    "test_file = \"../image_data/initialInt_262.csv\"\n",
    "test_output_file = \"../image_data/sample_555.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de81603c-cd0b-4414-9ded-aabe23a0af34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with h5py.File(train_file) as f:\n",
    "    print(f.keys())\n",
    "    beam_intensities = f[\"beamIntensities\"]\n",
    "    ip = ImageProcessing(beam_intensities)\n",
    "    s = ip.smallest_image_size()\n",
    "    print(s)\n",
    "\n",
    "    print(beam_intensities[0])\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(beam_intensities[0], aspect=\"auto\")\n",
    "    plt.show()\n",
    "\n",
    "    normalized_beam_intensities = (beam_intensities - np.mean(beam_intensities)) / np.std(beam_intensities)\n",
    "    print(normalized_beam_intensities[0])\n",
    "    \n",
    "    resized_images = []\n",
    "    for i in range(normalized_beam_intensities.shape[0]):\n",
    "        resized_images.append(ip.resize(normalized_beam_intensities[i], height=139, length=41))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(resized_images[0], aspect=\"auto\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(len(resized_images))\n",
    "    \n",
    "    initial_beam_intensity = pd.read_csv(\"initial_beam_intensity_csx.csv\", skiprows=1).to_numpy()\n",
    "    normalized_initial_beam_intensity = ( initial_beam_intensity - np.mean(initial_beam_intensity) ) / np.std(initial_beam_intensity)\n",
    "    resized_initial_beam_intensity = ip.resize(\n",
    "        normalized_initial_beam_intensity,\n",
    "        height=139,\n",
    "        length=41\n",
    "    )\n",
    "\n",
    "    with h5py.File(\"preprocessed_results.h5\", mode=\"w\") as preprocessed_results:\n",
    "        pi = preprocessed_results.create_dataset(\n",
    "            \"resized_initial_beam_intensity\",\n",
    "            (136, 40),\n",
    "            data = resized_initial_beam_intensity\n",
    "        )\n",
    "\n",
    "        pbi = preprocessed_results.create_dataset(\n",
    "            \"preprocessed_beam_intensities\",\n",
    "            (100, 136, 40)\n",
    "        )\n",
    "        for i, resized_image in enumerate(resized_images):\n",
    "            pbi[i] = resized_image\n",
    "        \n",
    "        param_vals = preprocessed_results.create_dataset_like(\"param_vals\", f[\"paramVals\"])\n",
    "        for i, param_val in enumerate(f[\"paramVals\"]):\n",
    "            param_vals[i] = param_val\n",
    "\n",
    "        params = preprocessed_results.create_dataset_like(\"params\", f[\"params\"])\n",
    "        for i, param in enumerate(f[\"params\"]):\n",
    "            params[i] = param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc4c64-fd23-4425-b6b1-4bfa3b97ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamIntensityDataset:\n",
    "    def __init__(self, beam_intensities, initial_beam_intensity, params, param_vals):\n",
    "        self.beam_intensities = beam_intensities\n",
    "        self.initial_beam_intensity = initial_beam_intensity\n",
    "        self.params = params\n",
    "        self.param_vals = param_vals\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.beam_intensities[index], self.initial_beam_intensity, self.param_vals[i]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.beam_intensities.shape[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be905134-5b4d-43e7-a02e-7ac7f03331af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = h5py.File('preprocessed_results.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51814305-54d1-43df-8f1a-913b41ffcd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "beamIntensities = np.array(data_file[\"preprocessed_beam_intensities\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e4934",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramVals = np.array(data_file[\"param_vals\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d448fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = np.array(data_file['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85129cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_intensity = np.array(data_file['resized_initial_beam_intensity'])\n",
    "plt.imshow(initial_intensity)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cf14a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bid = BeamIntensityDataset(beamIntensities, initial_intensity, parameters, paramVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcef737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f99525",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(bid, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489bfd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inten, initi, pvals = next(iter(training_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d448e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Intensity batch shape: {inten.size()}\")\n",
    "print(f\"Param Values batch shape: {pvals.size()}\")\n",
    "print(f\"Initial Intensity shape: {initi.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cfecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_img = inten[0].squeeze()\n",
    "label = pvals[0]\n",
    "plt.imshow(int_img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7567ef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_img = initi[0].squeeze()\n",
    "plt.imshow(init_img, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cf489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_beamline_simulation.u_net import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618731ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(136, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1474d077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea02092",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(\n",
    "    model,\n",
    "    input_data=(torch.ones(10,1, 136, 40), [0.1,0.1]),\n",
    "    col_names=(\"input_size\", \"output_size\", \"num_params\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575be0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_numpy = pd.read_csv(output_file, skiprows=1).to_numpy()\n",
    "normalized_train_output_image = (output_numpy - np.mean(output_numpy)) / np.std(output_numpy)\n",
    "resized_train_output_image = ip.resize(normalized_train_output_image[i], height=153, length=351)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae53087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_image = resized_train_output_image[None, None, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc92faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68913804",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tb_loss = []\n",
    "\n",
    "for e in range(0, 101):\n",
    "    for i, data in enumerate(training_dataloader):\n",
    "        train_inputs = data[0]\n",
    "        train_parameters = data[1]\n",
    "        \n",
    "        train_inputs = train_inputs[:, None, :, :]\n",
    "        \n",
    "        predictions = model(train_inputs, train_parameters)\n",
    "        crop_pred = predictions.detach()\n",
    "\n",
    "        loss = loss_func(predictions, train_output_image)\n",
    "        tb_loss.append(loss.data.numpy())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if e % 100 == 0:\n",
    "        # output the loss\n",
    "        print(\"Training Loss: \" + str(loss.data.numpy()))\n",
    "        print(\"Cropped Training Loss: \" + str(cropped_train_loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a70ce2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
