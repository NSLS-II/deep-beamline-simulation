{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca74a7c-d12d-4f3f-b6cb-bc33992307bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff921404-2b0e-4e5c-86e9-637ea4f1ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_beamline_simulation.u_net import ImageProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3773f1b2-ce34-4097-a93e-f5a6f3ffa48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import deep_beamline_simulation\n",
    "\n",
    "dbs_init_path = Path(deep_beamline_simulation.__file__)\n",
    "print(dbs_init_path)\n",
    "\n",
    "dbs_repository_path = dbs_init_path.parent.parent\n",
    "print(dbs_repository_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027625a2-20a7-4984-aa16-e122f22d3664",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training data was generated with Sirepo ML scripts for SRX and CSX simulations.\n",
    "\"\"\"\n",
    "#train_file = dbs_repository_path / \"NSLS-II-SRX-20/rsopt-srw-20220226232641/datasets/results.h5\"\n",
    "# 100\n",
    "# train_file = dbs_repository_path / \"NSLS-II-CSX-10/rsopt-srw-20220228140622/datasets/results.h5\"\n",
    "# 500\n",
    "train_file = dbs_repository_path / \"NSLS-II-CSX-10/rsopt-srw-20220228170315/datasets/results.h5\"\n",
    "# 1000\n",
    "#train_file = dbs_repository_path / \"NSLS-II-CSX-10/rsopt-srw-20220228175320/datasets/results.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7396fc65-d5ae-4560-aa34-4a76fec91bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initial intensity data was generated directly through Sirepo.\n",
    "\"\"\"\n",
    "\n",
    "#initial_beam_intensity_file = dbs_repository_path / \"NSLS-II-SRX-20/initial_beam_intensity_srx.csv\"\n",
    "initial_beam_intensity_file = dbs_repository_path / \"NSLS-II-CSX-10/initial_intensity.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de81603c-cd0b-4414-9ded-aabe23a0af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read results.h5 generated by a Sirepo ML script\n",
    "# preprocess the data and write a new h5 file\n",
    "with h5py.File(train_file) as f:\n",
    "\n",
    "    beam_intensities = f[\"beamIntensities\"]\n",
    "    ip = ImageProcessing(beam_intensities)\n",
    "    s = ip.smallest_image_size()\n",
    "\n",
    "    # this is used later\n",
    "    print(f\"params.shape: {f['params'].shape}\")\n",
    "    _parameter_count = f[\"params\"].shape[0]\n",
    "\n",
    "    # crop the images\n",
    "    h = beam_intensities.shape[1]\n",
    "    w = beam_intensities.shape[2]\n",
    "    hi = 0 + (h//3)\n",
    "    hj = h - (h//3)\n",
    "    wi = 0 + (w//3)\n",
    "    wj = w - (w//3)\n",
    "    \n",
    "    cropped_beam_intensities = beam_intensities[:, hi:hj, wi:wj]\n",
    "    plt.figure()\n",
    "    plt.imshow(beam_intensities[0], aspect=\"auto\")\n",
    "    plt.title(\"cropped image\")\n",
    "    plt.show()\n",
    "\n",
    "    log_cropped_beam_intensities = np.log( cropped_beam_intensities + 1e-10 )\n",
    "    plt.figure()\n",
    "    plt.hist(log_cropped_beam_intensities.flatten(), bins=100)\n",
    "    plt.title(\"log transformed cropped image data\")\n",
    "    plt.show()\n",
    "\n",
    "    normalized_log_cropped_beam_intensities = ( log_cropped_beam_intensities - np.mean(log_cropped_beam_intensities) ) / np.std(log_cropped_beam_intensities)\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "    axs[0].hist(normalized_log_cropped_beam_intensities.flatten(), bins=300)\n",
    "    axs[0].set_title(\"normalized log transformed cropped image data\")\n",
    "\n",
    "    axs[1].hist(np.std(normalized_log_cropped_beam_intensities, axis=(1,2)), bins=300)\n",
    "    axs[1].set_title(\"std\")\n",
    "    plt.show()\n",
    "\n",
    "    # this may not be necessary\n",
    "    bad_image_indices = []\n",
    "    good_image_indices = []\n",
    "    resized_images = []\n",
    "    \n",
    "    for i in range(normalized_log_cropped_beam_intensities.shape[0]):\n",
    "        std = np.std(normalized_log_cropped_beam_intensities[i])\n",
    "        if 1e-10 < std:\n",
    "            good_image_indices.append(i)\n",
    "        else:\n",
    "            print(f\"kicking out image {i} with std {std}\")\n",
    "            bad_image_indices.append(i)\n",
    "            #plt.figure()\n",
    "            #plt.imshow(normalized_log_cropped_beam_intensities[i], aspect=\"equal\")\n",
    "            #plt.show()\n",
    "\n",
    "        resized_images.append(\n",
    "            ip.resize(\n",
    "                normalized_log_cropped_beam_intensities[i],\n",
    "                height=128 + 3,\n",
    "                length=128 + 1\n",
    "            )\n",
    "        )\n",
    "\n",
    "    print(f\"bad image count: {len(bad_image_indices)}\")\n",
    "\n",
    "    initial_beam_intensity = pd.read_csv(initial_beam_intensity_file, skiprows=1).to_numpy()\n",
    "    min_initial_beam_intensity = np.min(initial_beam_intensity)\n",
    "    print(f\"min initial beam intensity {min_initial_beam_intensity}\")\n",
    "    if min_initial_beam_intensity > 0:\n",
    "        e = 0.0\n",
    "    elif min_initial_beam_intensity == 0.0:\n",
    "        e = 1e-10\n",
    "    else:\n",
    "        e = 1e-10 + np.abs(min_initial_beam_intensity)\n",
    "\n",
    "    log_initial_beam_intensity = np.log(\n",
    "        initial_beam_intensity + e\n",
    "    )\n",
    "    plt.figure()\n",
    "    plt.hist(log_initial_beam_intensity.flatten(), bins=100)\n",
    "    plt.title(\"log_initial_beam_intensity\")\n",
    "    plt.show()\n",
    "\n",
    "    normalized_initial_beam_intensity = ( log_initial_beam_intensity - np.mean(log_initial_beam_intensity) ) / np.std(log_initial_beam_intensity)\n",
    "    resized_initial_beam_intensity = ip.resize(\n",
    "        normalized_initial_beam_intensity,\n",
    "        height=128 + 3,\n",
    "        length=128 + 1\n",
    "    )\n",
    "\n",
    "    with h5py.File(\"preprocessed_results.h5\", mode=\"w\") as preprocessed_results:\n",
    "        good_image_count = len(good_image_indices)\n",
    "\n",
    "        pi_ds = preprocessed_results.create_dataset(\n",
    "            \"preprocessed_initial_beam_intensity\",\n",
    "            (128, 128)\n",
    "        )\n",
    "        pi_ds[:] = resized_initial_beam_intensity\n",
    "\n",
    "        params_ds = preprocessed_results.create_dataset_like(\"params\", f[\"params\"])\n",
    "        for i, param in enumerate(f[\"params\"]):\n",
    "            params_ds[i] = param\n",
    "\n",
    "        simulation_count = normalized_log_cropped_beam_intensities.shape[0]\n",
    "\n",
    "        pbi_ds = preprocessed_results.create_dataset(\n",
    "            \"preprocessed_beam_intensities\",\n",
    "            (good_image_count, 128, 128)\n",
    "        )\n",
    "        # pbi_ds = preprocessed_results.create_dataset(\n",
    "        #     \"preprocessed_beam_intensities\",\n",
    "        #     (f[\"beamIntensities\"].shape[0], 128, 128)\n",
    "        # )\n",
    "        \n",
    "        normalized_param_vals_ds = preprocessed_results.create_dataset(\n",
    "            \"preprocessed_param_vals\",\n",
    "            (good_image_count, f[\"paramVals\"].shape[1])\n",
    "        )\n",
    "        # normalized_param_vals_ds = preprocessed_results.create_dataset_like(\n",
    "        #     \"preprocessed_param_vals\",\n",
    "        #     f[\"paramVals\"]\n",
    "        # )\n",
    "\n",
    "        normalized_param_vals = (f[\"paramVals\"] - np.mean(f[\"paramVals\"])) / np.std(f[\"paramVals\"])\n",
    "        print(f\"normalized_param_vals\\n{normalized_param_vals}\")\n",
    "        \n",
    "        for i, good_i in enumerate(good_image_indices):\n",
    "            normalized_param_vals_ds[i] = normalized_param_vals[good_i]\n",
    "            pbi_ds[i] = resized_images[good_i]\n",
    "\n",
    "        # for i, resized_image in enumerate(resized_images):\n",
    "        #     normalized_param_vals_ds[i] = normalized_param_vals[i]\n",
    "        #     pbi_ds[i] = resized_images[i]\n",
    "\n",
    "        for good_i in good_image_indices[:10]:\n",
    "            #print(pbi_ds[i])\n",
    "            print(f\"std: {np.std(pbi_ds[good_i])}\")\n",
    "            f, ax = plt.subplots(nrows=1, ncols=3)\n",
    "            ax[0].imshow(beam_intensities[good_i], aspect=\"equal\")\n",
    "            ax[1].imshow(normalized_log_cropped_beam_intensities[good_i], aspect=\"equal\")\n",
    "            ax[2].imshow(resized_images[good_i], aspect=\"equal\")\n",
    "            plt.title(f\"{params_ds[:]}\\n{normalized_param_vals[good_i, :]}\")\n",
    "            plt.show()\n",
    "\n",
    "    with h5py.File(\"preprocessed_results.h5\", mode=\"r\") as preprocessed_results:\n",
    "        print(preprocessed_results.keys())\n",
    "        print(preprocessed_results[\"params\"])\n",
    "        print(preprocessed_results[\"params\"][:])\n",
    "        print(preprocessed_results[\"preprocessed_param_vals\"])\n",
    "        #print(preprocessed_results[\"preprocessed_initial_beam_intensity\"][0:2, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cac3fb-9467-4f1f-9efd-f2b41e4c159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(initial_beam_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be905134-5b4d-43e7-a02e-7ac7f03331af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378728fc-6430-4aff-a87c-81daecab3ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_beamline_model(parameter_count):\n",
    "    # build a \"down\" network, an \"up\" network, and a \"middle\" network\n",
    "    beamline_down = nn.Sequential(\n",
    "        nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=16,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(\n",
    "            in_channels=16,\n",
    "            out_channels=16,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(\n",
    "            kernel_size=2,\n",
    "            stride=2\n",
    "        ),\n",
    "\n",
    "        nn.Conv2d(\n",
    "            in_channels=16,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(\n",
    "            in_channels=32,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(\n",
    "            kernel_size=2,\n",
    "            stride=2\n",
    "        ),\n",
    "\n",
    "        nn.Conv2d(\n",
    "            in_channels=32,\n",
    "            out_channels=64,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=64,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "#         nn.MaxPool2d(\n",
    "#             kernel_size=2,\n",
    "#             stride=2\n",
    "#         ),\n",
    "\n",
    "#         nn.Conv2d(\n",
    "#             in_channels=64,\n",
    "#             out_channels=128,\n",
    "#             kernel_size=3,\n",
    "#             stride=1,\n",
    "#             padding=1\n",
    "#         ),\n",
    "#         nn.ReLU(),\n",
    "#         nn.Conv2d(\n",
    "#             in_channels=128,\n",
    "#             out_channels=128,\n",
    "#             kernel_size=3,\n",
    "#             stride=1,\n",
    "#             padding=1\n",
    "#         ),\n",
    "#         nn.ReLU(),\n",
    "    )\n",
    "    # output is [*, 32, 32, 32]\n",
    "\n",
    "    # take four parameters and expand them to a larger layer\n",
    "    beamline_middle = nn.Sequential(\n",
    "        nn.Linear(parameter_count, 8),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(8, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 1024),   # for 32x32 filter\n",
    "        #nn.ReLU()\n",
    "    )\n",
    "    # output is [*, 256]\n",
    "\n",
    "    beamline_up = nn.Sequential(\n",
    "#         nn.ConvTranspose2d(\n",
    "#             in_channels=128+1,\n",
    "#             out_channels=64,\n",
    "#             kernel_size=2,\n",
    "#             stride=2,\n",
    "#             padding=0\n",
    "#         ),\n",
    "#         nn.Dropout(0.25),\n",
    "#         nn.ReLU(),\n",
    "#         nn.Conv2d(\n",
    "#             in_channels=64,\n",
    "#             out_channels=64,\n",
    "#             kernel_size=3,\n",
    "#             stride=1,\n",
    "#             padding=1\n",
    "#         ),\n",
    "#         nn.ReLU(),\n",
    "\n",
    "        nn.ConvTranspose2d(\n",
    "            in_channels=64+1,\n",
    "            out_channels=32,\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "            padding=0\n",
    "        ),\n",
    "        # nn.Dropout(0.25),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(\n",
    "            in_channels=32,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        nn.ConvTranspose2d(\n",
    "            in_channels=32,\n",
    "            out_channels=16,\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "            padding=0\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(\n",
    "            in_channels=16,\n",
    "            out_channels=1,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "        # try ending with conv2d rather than relu to resolve learning failure\n",
    "        nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=1,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    class BeamlineModel(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.parameter_count = parameter_count\n",
    "            self.beamline_down = beamline_down\n",
    "            self.beamline_middle = beamline_middle\n",
    "            self.beamline_up = beamline_up\n",
    "\n",
    "        def forward(self, image, radius_scale_factor):\n",
    "            batch_count = image.shape[0]\n",
    "\n",
    "            # print(f\"image.shape: {image.shape}\")\n",
    "            # print(f\"radius_scale_factor.shape: {radius_scale_factor.shape}\")\n",
    "            \n",
    "            down_image_filters = self.beamline_down(image)\n",
    "            # print(f\"down_image_filters.shape: {down_image_filters.shape}\")\n",
    "            flat_down_image_filters = down_image_filters.reshape(batch_count, -1)\n",
    "            # print(f\"flat_down_image_filters shape: {flat_down_image_filters.shape}\")\n",
    "\n",
    "            radius_scale_factor_embedding = self.beamline_middle(radius_scale_factor)\n",
    "            # print(f\"radius_scale_factor_embedding shape: {radius_scale_factor_embedding.shape}\")\n",
    "\n",
    "            flat_down_image_filters_with_radius_scale_factor = torch.cat(\n",
    "                (\n",
    "                    flat_down_image_filters,\n",
    "                    radius_scale_factor_embedding\n",
    "                ),\n",
    "                dim=1\n",
    "            )\n",
    "            # print(f\"flat_down_image_filters_with_radius_scale_factor.shape: {flat_down_image_filters_with_radius_scale_factor.shape}\")\n",
    "            # for debugging\n",
    "            #return flat_down_image_filters_with_radius_scale_factor\n",
    "            \n",
    "            image_filters_with_radius_scale_factor = flat_down_image_filters_with_radius_scale_factor.reshape(\n",
    "                batch_count,\n",
    "                -1,\n",
    "                # if the smallest filter is 32x32 the radius scaled factor embedding must be 1024\n",
    "                32, \n",
    "                32\n",
    "            )\n",
    "            # print(f\"image_filters_with_radius_scale_factor.shape: {image_filters_with_radius_scale_factor.shape}\")\n",
    "            image = self.beamline_up(image_filters_with_radius_scale_factor)\n",
    "\n",
    "            return image\n",
    "\n",
    "    return BeamlineModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22373abc-acc7-4a8b-bbd5-faad058f35f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(\n",
    "    build_beamline_model(parameter_count=_parameter_count),\n",
    "    input_data=(torch.ones(2, 1, 128, 128), torch.ones(2, _parameter_count)),\n",
    "    col_names=(\"input_size\", \"output_size\", \"num_params\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc4c64-fd23-4425-b6b1-4bfa3b97ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamIntensityDataset:\n",
    "    def __init__(self, beam_intensities, initial_beam_intensity, params, param_vals):\n",
    "        self.beam_intensities = np.expand_dims(beam_intensities, axis=1)\n",
    "        self.initial_beam_intensity = np.expand_dims(initial_beam_intensity, axis=0)\n",
    "        self.params = params\n",
    "        self.param_vals = param_vals.astype(\"float32\")\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.beam_intensities[index], self.initial_beam_intensity, self.param_vals[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.beam_intensities.shape[0]\n",
    "\n",
    "    def report(self):\n",
    "        print(f\"length: {len(self)}\")\n",
    "        print(f\"initial beam intensity.shape:\\n{self.initial_beam_intensity.shape}\\n\")\n",
    "        print(f\"data shape:\\n{self.beam_intensities.shape}\\n\")\n",
    "        print(f\"data  at index 0:\\n{self[0]}\\n\")\n",
    "        print(f\"beamline parameters dtype:\\n\\t{self.params.dtype}\\n\")\n",
    "        print(f\"beamline parameters:\\n\\t{self.params}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d436962-f638-4684-8469-3694a480bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_beam_intensity_dataset():\n",
    "    with h5py.File(\"preprocessed_results.h5\", mode=\"r\") as preprocessed_results:\n",
    "        print(preprocessed_results.keys(), \"\\n\")\n",
    "\n",
    "        initial_beam_intensity_ds = preprocessed_results[\"preprocessed_initial_beam_intensity\"]\n",
    "        initial_beam_intensity = np.zeros_like(initial_beam_intensity_ds)\n",
    "        initial_beam_intensity[:] = initial_beam_intensity_ds[:]\n",
    "        print(f\"initial beam intensity:\\n{initial_beam_intensity}\\n\")\n",
    "\n",
    "        beam_intensities_ds = preprocessed_results[\"preprocessed_beam_intensities\"]\n",
    "        all_beam_intensities = np.zeros_like(beam_intensities_ds)\n",
    "        all_beam_intensities[:] = beam_intensities_ds[:]\n",
    "        print(f\"first of all beam intensities:\\n{all_beam_intensities[0]}\\n\")\n",
    "\n",
    "        beamline_parameters_ds = preprocessed_results[\"params\"]\n",
    "        # this works, but.....\n",
    "        beamline_parameters = np.zeros_like(beamline_parameters_ds)\n",
    "        beamline_parameters[:] = beamline_parameters_ds[:]\n",
    "        print(f\"beamline parameters:\\n\\t{beamline_parameters}\\n\")\n",
    "\n",
    "        beamline_parameter_values_ds = preprocessed_results[\"preprocessed_param_vals\"]\n",
    "        beamline_parameter_values = np.zeros_like(beamline_parameter_values_ds)\n",
    "        beamline_parameter_values[:] = beamline_parameter_values_ds[:]\n",
    "        print(f\"beamline parameter values:\\n{beamline_parameter_values}\\n\")\n",
    "\n",
    "        half = all_beam_intensities.shape[0] // 2\n",
    "        print(f\"half: {half}\")\n",
    "\n",
    "        training_beam_intensity_dataset = BeamIntensityDataset(\n",
    "            beam_intensities=all_beam_intensities[:half],\n",
    "            initial_beam_intensity=initial_beam_intensity,\n",
    "            params=beamline_parameters,\n",
    "            param_vals=beamline_parameter_values[:half]\n",
    "        )\n",
    "        training_beam_intensity_dataset.report()\n",
    "\n",
    "        testing_beam_intensity_dataset = BeamIntensityDataset(\n",
    "            beam_intensities=all_beam_intensities[:half],\n",
    "            initial_beam_intensity=initial_beam_intensity,\n",
    "            params=beamline_parameters,\n",
    "            param_vals=beamline_parameter_values[:half]          \n",
    "        )\n",
    "        testing_beam_intensity_dataset.report()\n",
    "\n",
    "demonstrate_beam_intensity_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d691662-5436-481c-ad54-798cdcb26c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_beam_intensity_dataloaders(batch_size=20):\n",
    "    with h5py.File(\"preprocessed_results.h5\", mode=\"r\") as preprocessed_results:\n",
    "        initial_beam_intensity_ds = preprocessed_results[\"preprocessed_initial_beam_intensity\"]\n",
    "        initial_beam_intensity = np.zeros_like(initial_beam_intensity_ds)\n",
    "        initial_beam_intensity[:] = initial_beam_intensity_ds[:]\n",
    "\n",
    "        beam_intensities_ds = preprocessed_results[\"preprocessed_beam_intensities\"]\n",
    "        beam_intensities = np.zeros_like(beam_intensities_ds)\n",
    "        beam_intensities[:] = beam_intensities_ds[:]\n",
    "\n",
    "        beamline_parameters_ds = preprocessed_results[\"params\"]\n",
    "        # this works, but.....\n",
    "        beamline_parameters = np.zeros_like(beamline_parameters_ds)\n",
    "        beamline_parameters[:] = beamline_parameters_ds[:]\n",
    "\n",
    "        beamline_parameter_values_ds = preprocessed_results[\"preprocessed_param_vals\"]\n",
    "        beamline_parameter_values = np.zeros_like(beamline_parameter_values_ds)\n",
    "        beamline_parameter_values[:] = beamline_parameter_values_ds[:]\n",
    "\n",
    "        half = beam_intensities.shape[0] // 2\n",
    "        two_thirds = 2 * (beam_intensities.shape[0] // 3)\n",
    "        \n",
    "        training_beam_intensity_dataset = BeamIntensityDataset(\n",
    "            beam_intensities=beam_intensities[:two_thirds],\n",
    "            initial_beam_intensity=initial_beam_intensity,\n",
    "            params=beamline_parameters,\n",
    "            param_vals=beamline_parameter_values[:two_thirds]\n",
    "        )\n",
    "        training_beam_intensity_dataloader = DataLoader(\n",
    "            training_beam_intensity_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        testing_beam_intensity_dataset = BeamIntensityDataset(\n",
    "            beam_intensities=beam_intensities[two_thirds:],\n",
    "            initial_beam_intensity=initial_beam_intensity,\n",
    "            params=beamline_parameters,\n",
    "            param_vals=beamline_parameter_values[two_thirds:]            \n",
    "        )\n",
    "        testing_beam_intensity_dataloader = DataLoader(\n",
    "            testing_beam_intensity_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "    return training_beam_intensity_dataloader, testing_beam_intensity_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d0ea99-abd0-4ab8-9b3d-9eb7ec6b426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader, testing_dataloader = build_beam_intensity_dataloaders(batch_size=5)\n",
    "for target_intensities, input_intensities, input_params in training_dataloader:\n",
    "    print(f\"target_intensities.shape : {target_intensities.shape}\")\n",
    "    print(f\"input_intensities.shape  : {input_intensities.shape}\")\n",
    "    print(f\"input_params.shape       : {input_params.shape}\")\n",
    "    print()\n",
    "    break\n",
    "    \n",
    "for target_intensities, input_intensities, input_params in testing_dataloader:\n",
    "    print(f\"target_intensities.shape : {target_intensities.shape}\")\n",
    "    print(f\"input_intensities.shape  : {input_intensities.shape}\")\n",
    "    print(f\"input_params.shape       : {input_params.shape}\")\n",
    "    print\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8147429f-59b0-410c-b27e-0b305ecda56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    circle_squasher_model,\n",
    "    optimizer,\n",
    "    loss_function,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    epoch_count\n",
    "):\n",
    "\n",
    "    training_loss_list = []\n",
    "    testing_loss_list = []\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    circle_squasher_model.to(device)\n",
    "\n",
    "    for epoch_i in range(epoch_count):\n",
    "        training_loss = 0.0\n",
    "        circle_squasher_model.train()\n",
    "        for correct_squashed_circle_images, circle_images, radius_scale_factors in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # torch calls circle_images 'inputs'\n",
    "            circle_images = circle_images.to(device)\n",
    "            correct_squashed_circle_images = correct_squashed_circle_images.to(device)\n",
    "            radius_scale_factors = radius_scale_factors.to(device)\n",
    "\n",
    "            predicted_squashed_circle_images = circle_squasher_model(\n",
    "                circle_images,\n",
    "                radius_scale_factors\n",
    "            )\n",
    "\n",
    "            loss = loss_function(\n",
    "                predicted_squashed_circle_images,\n",
    "                correct_squashed_circle_images\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            training_loss += loss.data.item()\n",
    "\n",
    "        #training_loss /= len(train_dataloader.dataset)\n",
    "        training_loss_list.append(training_loss)\n",
    "        \n",
    "        test_loss = 0.0\n",
    "        circle_squasher_model.eval()\n",
    "        for correct_squashed_circle_images, circle_images, radius_scale_factors in test_dataloader:\n",
    "\n",
    "            # torch calls circle_images 'inputs'\n",
    "            circle_images = circle_images.to(device)\n",
    "            correct_squashed_circle_images = correct_squashed_circle_images.to(device)\n",
    "            radius_scale_factors = radius_scale_factors.to(device)\n",
    "\n",
    "            predicted_squashed_circle_images = circle_squasher_model(\n",
    "                circle_images,\n",
    "                radius_scale_factors\n",
    "            )\n",
    "\n",
    "            loss = loss_function(predicted_squashed_circle_images, correct_squashed_circle_images)\n",
    "            test_loss += loss.data.item()\n",
    "\n",
    "        #test_loss /= len(test_dataloader.dataset)\n",
    "        testing_loss_list.append(test_loss)\n",
    "\n",
    "        if epoch_i % 100 == 0:\n",
    "            print(\n",
    "                'Epoch: {}, Training Loss: {:.5f}, Test Loss: {:.5f}'.format(\n",
    "                    epoch_i, training_loss, test_loss\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return training_loss_list, testing_loss_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942c5fac-e723-4b36-8caf-a964dc19e99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: restart training if learning is very slow\n",
    "import torch.optim\n",
    "\n",
    "simulation_count = len(resized_images)\n",
    "\n",
    "# batch_size = 5 for SRX 20 simulations\n",
    "#beamline = \"SRX\"\n",
    "#train_dataloader, test_dataloader = build_beam_intensity_dataloaders(batch_size=5)\n",
    "#epoch_count = 2500\n",
    "\n",
    "# batch_size = 50 for CSX 500 simulations\n",
    "beamline = \"CSX\"\n",
    "train_dataloader, test_dataloader = build_beam_intensity_dataloaders(batch_size=50)\n",
    "epoch_count = 300  # 1000 is good if you have the time\n",
    "\n",
    "print(f\"train_dataloader length {len(train_dataloader)}\")\n",
    "print(f\"test_dataloader length {len(test_dataloader)}\")\n",
    "beamline_model = build_beamline_model(parameter_count=_parameter_count)\n",
    "training_loss_list, testing_loss_list = train(\n",
    "    beamline_model,\n",
    "    torch.optim.Adam(beamline_model.parameters()),\n",
    "    torch.nn.MSELoss(),\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    epoch_count=epoch_count\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00aea61-b9cc-4654-b715-1627ce566582",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(training_loss_list, label=\"training loss\")\n",
    "plt.plot(testing_loss_list, label=\"testing loss\")\n",
    "plt.title(f\"{beamline} {simulation_count} simulations\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7027620-ce8b-436a-aaa0-ba30ffbd1717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out the model\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "train_dataloader, test_dataloader = build_beam_intensity_dataloaders()\n",
    "print(f\"train_dataloader length {len(train_dataloader)}\")\n",
    "print(f\"test_dataloader length {len(test_dataloader)}\")\n",
    "\n",
    "beamline_model.eval()\n",
    "for a_circle_target_image, a_circle_input_image, radius_scale_factor in test_dataloader:\n",
    "    print(f\"input shape : {a_circle_input_image.shape}\")\n",
    "    print(f\"radius_scale_factor: {radius_scale_factor[0, :]}\")\n",
    "\n",
    "    a_squashed_circle_tensor = beamline_model(\n",
    "        a_circle_input_image.to(device),\n",
    "        radius_scale_factor.to(device)\n",
    "    )\n",
    "    a_squashed_circle_image = a_squashed_circle_tensor.cpu().detach().numpy()\n",
    "    \n",
    "    print(f\"output shape: {a_squashed_circle_image.shape}\")\n",
    "    #print(f\"output:\\n{a_squashed_circle_image[0, 0, :, :]}\")\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3)\n",
    "    #for i, (r, c) in enumerate(itertools.product(range(1), range(2))):\n",
    "    #print('circle radiuses: {}'.format(circle_radiuses))\n",
    "    axs[0].imshow(a_circle_input_image[0, 0, :, :], origin=\"lower\")\n",
    "    axs[0].set_title(\"initial\")\n",
    "    axs[0].axis(\"off\")\n",
    "    axs[1].imshow(a_circle_target_image[0, 0, :, :], origin=\"lower\")\n",
    "    axs[1].set_title(\"target\")\n",
    "    axs[1].axis(\"off\")\n",
    "    axs[1].set_xlabel(radius_scale_factor[0, :])\n",
    "    axs[2].imshow(a_squashed_circle_image[0, 0, :, :], origin=\"lower\")\n",
    "    axs[2].set_title(\"output\")\n",
    "    axs[2].axis(\"off\")\n",
    "    #print(np.array(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe513a9-beda-4ee2-a1bf-12946aabfe23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
